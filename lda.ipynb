{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Test a Python/NumPy Implementation of LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "samples, _ = fetch_20newsgroups(\n",
    "    remove=('headers', 'footers', 'quotes'),\n",
    "    shuffle=True,\n",
    "    random_state=1,\n",
    "    return_X_y=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Tokenize samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = re.compile(r'\\b[a-z]+\\b')\n",
    "samples = [pattern.findall(s.lower()) for s in samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Filter stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stopwords.txt\", \"r\") as f:\n",
    "    stopword_list = set(f.read().splitlines())\n",
    "    \n",
    "samples = [[w for w in s if w not in stopword_list] for s in samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Use only a subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 2000\n",
    "subset = samples[:N_SAMPLES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Import and run Python LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from pstats import SortKey\n",
    "from py_lda import PythonLDA\n",
    "\n",
    "py_lda = PythonLDA(corpus=subset, T=20, S=100, beta=0.01, alpha=0.1)\n",
    "cProfile.runctx('py_lda.fit()', globals(), locals(), filename=\"py_stats.txt\")\n",
    "py_lda.print_topics()\n",
    "pstats.Stats('py_stats.txt').strip_dirs().sort_stats(SortKey.TIME).print_stats(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2 Test a Cython Implementation of LDA w/CGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Prepare notebook for Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling cy_lda.pyx because it changed.\n",
      "[1/1] Cythonizing cy_lda.pyx\n",
      "running build_ext\n",
      "building 'cy_lda' extension\n",
      "creating build\n",
      "creating build/temp.linux-x86_64-3.8\n",
      "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/home/joshua/repos/cython-lda/venv/include -I/usr/include/python3.8 -c cy_lda.c -o build/temp.linux-x86_64-3.8/cy_lda.o\n",
      "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/cy_lda.o -o /home/joshua/repos/cython-lda/cy_lda.cpython-38-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "!python3 cy_setup.py build_ext --inplace --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Repeat steps 1.1-1.4, load Cython extension, and test LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0: -1435782.903896\n",
      "Iteration 10: -1376416.068089\n",
      "Iteration 20: -1353688.998181\n",
      "Iteration 30: -1339322.551705\n",
      "Iteration 40: -1329561.610376\n",
      "Iteration 50: -1323316.220194\n",
      "Iteration 60: -1318461.470116\n",
      "Iteration 70: -1314677.727184\n",
      "Iteration 80: -1311703.591040\n",
      "Iteration 90: -1309066.440714\n",
      "Iteration 100: -1306312.818619\n",
      "\n",
      "Fri Jul 17 17:28:26 2020    cy_stats.txt\n",
      "\n",
      "         119 function calls in 3.542 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      101    3.471    0.034    3.471    0.034 cy_lda.pyx:103(_sample_topics)\n",
      "       11    0.070    0.006    0.070    0.006 cy_lda.pyx:75(_log_prob)\n",
      "        1    0.001    0.001    3.542    3.542 cy_lda.pyx:152(inference_loop)\n",
      "        1    0.000    0.000    3.542    3.542 <string>:1(<module>)\n",
      "        1    0.000    0.000    3.542    3.542 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    3.542    3.542 {method 'fit' of 'cy_lda.CythonLDA' objects}\n",
      "        1    0.000    0.000    3.542    3.542 cy_lda.pyx:168(fit (wrapper))\n",
      "        1    0.000    0.000    3.542    3.542 cy_lda.pyx:168(fit)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "\n",
    "# 1.1 Load samples\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "samples, _ = fetch_20newsgroups(\n",
    "    remove=('headers', 'footers', 'quotes'),\n",
    "    shuffle=True,\n",
    "    random_state=1,\n",
    "    return_X_y=True\n",
    ")\n",
    "\n",
    "# 1.2 Tokenize samples\n",
    "import re\n",
    "\n",
    "pattern = re.compile(r'\\b[a-z]+\\b')\n",
    "samples = [pattern.findall(s.lower()) for s in samples]\n",
    "\n",
    "# 1.3 Filter stopwords\n",
    "with open(\"stopwords.txt\", \"r\") as f:\n",
    "    stopword_list = set(f.read().splitlines())\n",
    "samples = [[w for w in s if w not in stopword_list] for s in samples]\n",
    "\n",
    "# 1.4 Use only a subset\n",
    "N_SAMPLES = 2000\n",
    "subset = samples[:N_SAMPLES]\n",
    "\n",
    "# Test LDA\n",
    "from cy_lda import CythonLDA\n",
    "import cProfile\n",
    "import pstats\n",
    "from pstats import SortKey\n",
    "\n",
    "cy_lda = CythonLDA(corpus=subset, T=20, S=100, beta=0.01, alpha=0.1)\n",
    "cProfile.runctx('cy_lda.fit()', globals(), locals(), filename=\"cy_stats.txt\")\n",
    "pstats.Stats('cy_stats.txt').strip_dirs().sort_stats(SortKey.TIME).print_stats(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}